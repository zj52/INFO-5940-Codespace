{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Pull base URL and API key from environment variables\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "import math\n",
    "import argparse\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def split_audio(in_path: Path, chunk_minutes: int, tmp_dir: Path):\n",
    "    audio = AudioSegment.from_file(in_path)\n",
    "    chunk_ms = chunk_minutes * 60_000\n",
    "    total_chunks = math.ceil(len(audio) / chunk_ms)\n",
    "    paths = []\n",
    "    for i in range(total_chunks):\n",
    "        start = i * chunk_ms\n",
    "        end = min((i + 1) * chunk_ms, len(audio))\n",
    "        chunk = audio[start:end]\n",
    "        out_path = tmp_dir / f\"chunk_{i:03d}.mp3\"\n",
    "        chunk.export(out_path, format=\"mp3\")\n",
    "        paths.append(out_path)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def transcribe_file(audio_path: Path, model: str):\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        tr = client.audio.transcriptions.create(model=model, file=f)\n",
    "    return tr.text.strip()\n",
    "\n",
    "\n",
    "def chat_summarize(text: str, model: str, system_prompt: str, instruction: str):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"{instruction}\\n\\n{text}\"})\n",
    "    resp = client.chat.completions.create(model=model, messages=messages, temperature=0.2)\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Chunk, transcribe, and summarize an audio file.\")\n",
    "    parser.add_argument(\"audio\", type=Path, help=\"Path to input audio file (mp3, wav, m4a, etc.)\")\n",
    "    parser.add_argument(\"--chunk-minutes\", type=int, default=10, help=\"Chunk length in minutes\")\n",
    "    parser.add_argument(\"--out-dir\", type=Path, default=Path(\"out\"), help=\"Directory for outputs\")\n",
    "    parser.add_argument(\"--whisper-model\", default=\"whisper-1\", help=\"OpenAI transcription model\")\n",
    "    parser.add_argument(\"--summary-model\", default=\"gpt-4o-mini\", help=\"OpenAI summarization model\")\n",
    "    parser.add_argument(\"--system-prompt-file\", type=Path, default=None, help=\"Optional system prompt file\")\n",
    "    parser.add_argument(\"--keep-chunks\", action=\"store_true\", help=\"Keep temporary audio chunks\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # read system prompt if provided\n",
    "    system_prompt = \"\"\n",
    "    if args.system_prompt_file and args.system_prompt_file.exists():\n",
    "        system_prompt = args.system_prompt_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # ensure output dir\n",
    "    args.out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # make temp dir for audio chunks\n",
    "    temp_dir_ctx = tempfile.TemporaryDirectory()\n",
    "    tmp_dir = Path(temp_dir_ctx.name)\n",
    "\n",
    "    print(\"Splitting audio...\")\n",
    "    chunk_paths = split_audio(args.audio, args.chunk_minutes, tmp_dir)\n",
    "    print(f\"Created {len(chunk_paths)} chunks\")\n",
    "\n",
    "    # transcribe each chunk\n",
    "    chunk_transcripts = []\n",
    "    for i, p in enumerate(chunk_paths):\n",
    "        print(f\"Transcribing chunk {i+1}/{len(chunk_paths)}: {p.name}\")\n",
    "        text = transcribe_file(p, args.whisper_model)\n",
    "        chunk_transcripts.append(text)\n",
    "\n",
    "    # save combined transcript\n",
    "    combined_transcript = \"\\n\\n\".join(\n",
    "        [f\"[Chunk {i+1}]\\n{text}\" for i, text in enumerate(chunk_transcripts)]\n",
    "    )\n",
    "    (args.out_dir / \"combined_transcript.txt\").write_text(combined_transcript, encoding=\"utf-8\")\n",
    "    print(f\"Wrote {args.out_dir / 'combined_transcript.txt'}\")\n",
    "\n",
    "    # summarize each chunk\n",
    "    print(\"Summarizing chunks...\")\n",
    "    per_chunk_summaries = []\n",
    "    for i, text in enumerate(chunk_transcripts):\n",
    "        instruction = (\n",
    "            \"Summarize this transcript section into concise bullet points. \"\n",
    "            \"Capture key topics, decisions, action items with owners and due dates if stated, \"\n",
    "            \"and any open questions. Keep it faithful and factual.\"\n",
    "        )\n",
    "        s = chat_summarize(text, args.summary_model, system_prompt, instruction)\n",
    "        per_chunk_summaries.append(f\"[Chunk {i+1} summary]\\n{s}\")\n",
    "\n",
    "    chunk_summaries_text = \"\\n\\n\".join(per_chunk_summaries)\n",
    "    (args.out_dir / \"chunk_summaries.txt\").write_text(chunk_summaries_text, encoding=\"utf-8\")\n",
    "    print(f\"Wrote {args.out_dir / 'chunk_summaries.txt'}\")\n",
    "\n",
    "    # final overall summary from per-chunk summaries\n",
    "    print(\"Creating final overall summary...\")\n",
    "    final_instruction = (\n",
    "        \"Using the chunk summaries below, produce a single cohesive meeting-style summary with \"\n",
    "        \"sections: Overview, Key Topics, Decisions, Action Items, Notable Quotes, Open Questions. \"\n",
    "        \"Do not invent details not present in the summaries.\"\n",
    "    )\n",
    "    final_summary = chat_summarize(chunk_summaries_text, args.summary_model, system_prompt, final_instruction)\n",
    "    (args.out_dir / \"final_summary.txt\").write_text(final_summary, encoding=\"utf-8\")\n",
    "    print(f\"Wrote {args.out_dir / 'final_summary.txt'}\")\n",
    "\n",
    "    # clean up temp chunks unless requested to keep\n",
    "    if args.keep_chunks:\n",
    "        keep_dir = args.out_dir / \"chunks_audio\"\n",
    "        keep_dir.mkdir(exist_ok=True)\n",
    "        for p in chunk_paths:\n",
    "            p.replace(keep_dir / p.name)\n",
    "        print(f\"Kept chunks in {keep_dir}\")\n",
    "    else:\n",
    "        temp_dir_ctx.cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
